{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import psycopg2\n",
    "import getpass\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os.path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature file names\n",
    "feature_files = ['admission_type', 'age', 'aids_haem_mets', 'bicarb', 'bilirubin', 'blood_pressure', 'fio2', \\\n",
    "            'gcs_eyes', 'gcs_motor', 'gcs_verbal', 'heart_rate', 'pao2', 'potassium', 'sodium', 'temperature', 'urea', 'urine', 'wbc']\n",
    "\n",
    "# Define processed feature names\n",
    "feature_names = ['admission_type', 'age', 'aids_haem_mets', 'bicarb_24h', 'bilirubin_24h', 'bp_24h', 'fio2_24h', \\\n",
    "            'gcs_eyes_24h', 'gcs_motor_24h', 'gcs_verbal_24h', 'hr_24h', 'pao2_24h', 'potassium_24h', 'sodium_24h', 'temp_24h', 'urea_24h', 'urine_24h', 'wbc_24h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files loaded!\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "for i in range(len(feature_files)):\n",
    "    _data = np.load('res/{}.npy'.format(feature_files[i]), allow_pickle=True).tolist()\n",
    "    exec(\"{} = _data['{}']\".format(feature_names[i], feature_names[i]))\n",
    "print(\"All files loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admission_type: \n",
      "(38549, 4)\n",
      "\n",
      "age: \n",
      "(38549, 2)\n",
      "\n",
      "aids_haem_mets: \n",
      "(38549, 4)\n",
      "\n",
      "bicarb_24h: \n",
      "(38549, 25, 1)\n",
      "\n",
      "bilirubin_24h: \n",
      "(38549, 25, 1)\n",
      "\n",
      "bp_24h: \n",
      "(38549, 25, 1)\n",
      "\n",
      "fio2_24h: \n",
      "(38549, 25, 1)\n",
      "\n",
      "gcs_eyes_24h: \n",
      "(38549, 25, 1)\n",
      "\n",
      "gcs_motor_24h: \n",
      "(38549, 25, 1)\n",
      "\n",
      "gcs_verbal_24h: \n",
      "(38549, 25, 1)\n",
      "\n",
      "hr_24h: \n",
      "(38549, 25, 1)\n",
      "\n",
      "pao2_24h: \n",
      "(38549, 25, 1)\n",
      "\n",
      "potassium_24h: \n",
      "(38549, 25, 1)\n",
      "\n",
      "sodium_24h: \n",
      "(38549, 25, 1)\n",
      "\n",
      "temp_24h: \n",
      "(38549, 25, 1)\n",
      "\n",
      "urea_24h: \n",
      "(38549, 25, 1)\n",
      "\n",
      "urine_24h: \n",
      "(38549, 25, 1)\n",
      "\n",
      "wbc_24h: \n",
      "(38549, 25, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check shape of files\n",
    "for i in range(len(feature_files)):\n",
    "    print(\"{}: \".format(feature_names[i]))\n",
    "    exec(\"shape = np.shape({})\\nprint(shape)\".format(feature_names[i]))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched_surg_24h:  (38549, 25)\n",
      "unsched_surg_24h:  (38549, 25)\n",
      "medical_24h:  (38549, 25)\n",
      "age_24h:  (38549, 25)\n",
      "aids_24h:  (38549, 25)\n",
      "haem_24h:  (38549, 25)\n",
      "mets_24h:  (38549, 25)\n"
     ]
    }
   ],
   "source": [
    "# Broadcast static features so they have 24 time steps\n",
    "sched_surg_24h = np.column_stack((admission_type[:,0], np.tile(admission_type[:,1], (24,1)).T))\n",
    "unsched_surg_24h = np.column_stack((admission_type[:,0], np.tile(admission_type[:,2], (24,1)).T))\n",
    "medical_24h = np.column_stack((admission_type[:,0], np.tile(admission_type[:,3], (24,1)).T))\n",
    "age_24h = np.column_stack((age[:,0], np.tile(age[:,1], (24,1)).T))\n",
    "aids_24h = np.column_stack((aids_haem_mets[:,0], np.tile(aids_haem_mets[:,1], (24,1)).T))\n",
    "haem_24h = np.column_stack((aids_haem_mets[:,0], np.tile(aids_haem_mets[:,2], (24,1)).T))\n",
    "mets_24h = np.column_stack((aids_haem_mets[:,0], np.tile(aids_haem_mets[:,3], (24,1)).T))\n",
    "\n",
    "# Check the dimensions are correct\n",
    "print(\"sched_surg_24h: \", np.shape(sched_surg_24h))\n",
    "print(\"unsched_surg_24h: \", np.shape(unsched_surg_24h))\n",
    "print(\"medical_24h: \", np.shape(medical_24h))\n",
    "print(\"age_24h: \", np.shape(age_24h))\n",
    "print(\"aids_24h: \", np.shape(aids_24h))\n",
    "print(\"haem_24h: \", np.shape(haem_24h))\n",
    "print(\"mets_24h: \", np.shape(mets_24h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:  (38549, 22, 24)\n"
     ]
    }
   ],
   "source": [
    "# Stack all features into one array\n",
    "dataset = np.dstack((sched_surg_24h, unsched_surg_24h, medical_24h, age_24h, aids_24h, haem_24h, mets_24h, bicarb_24h, bilirubin_24h, bp_24h, \\\n",
    "                   fio2_24h, gcs_eyes_24h, gcs_motor_24h, gcs_verbal_24h, hr_24h, pao2_24h, potassium_24h, sodium_24h, temp_24h, urea_24h, urine_24h, wbc_24h))\n",
    "\n",
    "# Remove the patient IDs\n",
    "dataset = dataset[:,1:,:]\n",
    "\n",
    "# Transpose dataset so it is in the shape (m,n,T)\n",
    "dataset = np.transpose(dataset, (0,2,1))\n",
    "\n",
    "# Check the shape of the dataset\n",
    "print(\"dataset: \", np.shape(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mortality:  (38549,)\n"
     ]
    }
   ],
   "source": [
    "# Load the mortality data\n",
    "_data = np.load('res/mortality.npy', allow_pickle=True).tolist()\n",
    "mortality = _data['mortality']\n",
    "\n",
    "# Remove the patient IDs\n",
    "mortality = mortality[:,1]\n",
    "\n",
    "# Check the shape of the mortality\n",
    "print(\"mortality: \", np.shape(mortality))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (30839, 22, 24)\n",
      "y_train: (30839,)\n",
      "X_val: (3855, 22, 24)\n",
      "y_val: (3855,)\n",
      "X_test: (3855, 22, 24)\n",
      "y_test: (3855,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset, mortality, train_size=0.8, random_state=42)\n",
    "\n",
    "# Split the test data into validation and test sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, train_size=0.5, random_state=42)\n",
    "\n",
    "# Check the shapes of the outputs\n",
    "print(\"X_train: {}\".format(np.shape(X_train)))\n",
    "print(\"y_train: {}\".format(np.shape(y_train)))\n",
    "print(\"X_val: {}\".format(np.shape(X_val)))\n",
    "print(\"y_val: {}\".format(np.shape(y_val)))\n",
    "print(\"X_test: {}\".format(np.shape(X_test)))\n",
    "print(\"y_test: {}\".format(np.shape(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of patients: 38549\n",
      "No. of patients in train, val, test sets: 30839, 3855, 3855\n",
      "No. of patients who died in hospital in train, val, test sets: 3458.0, 417.0, 445.0\n",
      "Proportion of patients who died in hospital in train, val, test sets: 11.213%, 10.817%, 11.543%\n"
     ]
    }
   ],
   "source": [
    "# Print information about the created arrays\n",
    "print(\"No. of patients: {}\".format(len(dataset)))\n",
    "print(\"No. of patients in train, val, test sets: {}, {}, {}\".format(len(X_train), len(X_val), len(X_test)))\n",
    "print(\"No. of patients who died in hospital in train, val, test sets: {}, {}, {}\".format(str(sum(y_train)), str(sum(y_val)), str(sum(y_test))))\n",
    "print(\"Proportion of patients who died in hospital in train, val, test sets: {}%, {}%, {}%\".format(round(sum(y_train)/len(y_train)*100,3), round(sum(y_val)/len(y_val)*100,3), round(sum(y_test)/len(y_test)*100,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_norm: (30839, 22, 24)\n",
      "X_val_norm: (3855, 22, 24)\n",
      "X_test_norm: (3855, 22, 24)\n"
     ]
    }
   ],
   "source": [
    "# Define shape\n",
    "m, n, T = np.shape(X_train)\n",
    "X_train_norm = np.zeros((m,n,T))\n",
    "    \n",
    "# Iterate through each feature\n",
    "for i in range(n):\n",
    "    X_train_norm[:,i,:] = MinMaxScaler().fit_transform(X_train[:,i,:])\n",
    "    \n",
    "# Print the shape of the normalised array\n",
    "print(\"X_train_norm: {}\".format(np.shape(X_train_norm)))\n",
    "\n",
    "# Define shape\n",
    "m, n, T = np.shape(X_val)\n",
    "X_val_norm = np.zeros((m,n,T))\n",
    "    \n",
    "# Iterate through each feature\n",
    "for i in range(n):\n",
    "    X_val_norm[:,i,:] = MinMaxScaler().fit_transform(X_val[:,i,:])\n",
    "    \n",
    "# Print the shape of the normalised array\n",
    "print(\"X_val_norm: {}\".format(np.shape(X_val_norm)))\n",
    "\n",
    "# Define shape\n",
    "m, n, T = np.shape(X_test)\n",
    "X_test_norm = np.zeros((m,n,T))\n",
    "    \n",
    "# Iterate through each feature\n",
    "for i in range(n):\n",
    "    X_test_norm[:,i,:] = MinMaxScaler().fit_transform(X_test[:,i,:])\n",
    "    \n",
    "# Print the shape of the normalised array\n",
    "print(\"X_test_norm: {}\".format(np.shape(X_test_norm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved!\n"
     ]
    }
   ],
   "source": [
    "# Save to data.npy\n",
    "if not os.path.exists('./res'):\n",
    "    os.makedirs('./res')\n",
    "\n",
    "tosave = {'X_train': X_train_norm, 'y_train': y_train, 'X_val': X_val_norm, 'y_val': y_val, 'X_test': X_test_norm, 'y_test': y_test}\n",
    "np.save('res/data.npy',tosave)\n",
    "print(\"Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
